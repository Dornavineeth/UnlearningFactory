# @package _global_

defaults:
  - override /model: Llama-2-7b-chat-hf
  - override /trainer: finetune
  - override /data/datasets@data.train: TOFU_QA_retain

trainer:
  args:
    learning_rate: 5e-5
    weight_decay: 0.01
    num_train_epochs: 10
    save_strategy: steps
    save_steps: 0.5