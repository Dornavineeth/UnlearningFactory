# @package _global_

defaults:
  - override /model: Llama-2-7b-chat-hf
  - override /trainer: finetune
  - override /data/datasets@data.train: TOFU_QA_retain
  - override /data/datasets@data.eval: TOFU_QA_forget_para

mode: finetune
trainer:
  args:
    learning_rate: 5e-5
    weight_decay: 0.01
    warmup_epochs: 1.0 # custom parameter
    num_train_epochs: 10
    save_strategy: steps
    save_steps: 0.5