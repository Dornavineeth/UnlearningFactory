model_args:
  pretrained_model_name_or_path: locuslab/tofu_ft_llama2-7b
  attn_implementation: 'flash_attention_2'
  torch_dtype: bfloat16
tokenizer_args:
  pretrained_model_name_or_path: locuslab/tofu_ft_llama2-7b
template_args: # Used in creating prompts for the dataset. See src/data/utils.py#preprocess_chat_instance.
# following https://www.reddit.com/r/LocalLLaMA/comments/1561vn5/here_is_a_practical_multiturn_llama2chat_prompt/
  apply_chat_template: False
  user_start_tag: "[INST] "
  user_end_tag: " [/INST]"
  asst_start_tag: ""
  asst_end_tag: ""